{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bg/xs82ss7x45n2y6rrty58fjd40000gn/T/ipykernel_17792/2162427038.py:7: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your path to one of the subjects from Action-Net\n",
    "emg_annotations = pd.read_pickle(\"emg_annotations/S04_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "num_samples = 20\n",
    "\n",
    "def rectify_signal(data):\n",
    "    return np.abs(data)\n",
    "\n",
    "def low_pass_filter(data, fs, cutoff):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(4, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def preprocess_row(row, start_time=0, duration=10, num_samples=100, side=\"left\", num_channels=8):\n",
    "    timestamps = row[f'myo_{side}_timestamps']\n",
    "    records = row[f'myo_{side}_readings']\n",
    "    \n",
    "    # Pre-processing steps\n",
    "    # 1. Rectify the signal\n",
    "    rectified_data = rectify_signal(records)\n",
    "    rectified_data = rectified_data.T\n",
    "\n",
    "    # 2. Low pass filter 5 Hz\n",
    "    fs = 160\n",
    "    cutoff = 5\n",
    "    filtered_data = np.zeros_like(rectified_data)\n",
    "    for i in range(num_channels):\n",
    "        filtered_data[i] = low_pass_filter(rectified_data[i], fs, cutoff)\n",
    "    filtered_data = filtered_data.T\n",
    "    # 3. Apply normalization\n",
    "    normalized_data = 2 * (filtered_data - np.min(filtered_data)) / (np.max(filtered_data) - np.min(filtered_data)) - 1\n",
    "\n",
    "    # Interpolate data for each row\n",
    "    interpolation_time = np.linspace(start_time, start_time + duration, num_samples)  # Assuming the last timestamp represents the end time\n",
    "    interpolator = interp1d(timestamps, normalized_data, kind='linear', fill_value='extrapolate', axis=0)\n",
    "    interpolated_data = interpolator(interpolation_time)\n",
    "\n",
    "    return interpolated_data\n",
    "\n",
    "\n",
    "# Function to process each row of the DataFrame\n",
    "def process_row(row, num_samples=100, duration=10, num_clips = 1):\n",
    "    # Preprocess the data\n",
    "    sides = [\"left\", \"right\"]\n",
    "    tot_time = row[\"myo_left_timestamps\"][-1] - row[\"myo_left_timestamps\"][0]\n",
    "    return_rows = []\n",
    "    start_time = np.linspace(0, tot_time-duration, num_clips)\n",
    "    for st in start_time:\n",
    "        final_data = {}\n",
    "        if duration < tot_time:\n",
    "            for side in sides:\n",
    "                final_data[side] = preprocess_row(row, st, duration, num_samples, side)\n",
    "        else:\n",
    "            for side in sides:\n",
    "                final_data[side] = preprocess_row(row, 0, tot_time, num_samples, side)\n",
    "        final_data = np.hstack((final_data[\"left\"], final_data[\"right\"]))\n",
    "        return_rows.append((row[\"description\"], final_data))\n",
    "    return return_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description  \\\n",
      "0  Get/replace items from refrigerator/cabinets/d...   \n",
      "1  Get/replace items from refrigerator/cabinets/d...   \n",
      "2  Get/replace items from refrigerator/cabinets/d...   \n",
      "3  Get/replace items from refrigerator/cabinets/d...   \n",
      "4  Get/replace items from refrigerator/cabinets/d...   \n",
      "\n",
      "                                        myo_readings  \n",
      "0  [[-0.7846153846153846, -0.8461538461538461, -4...  \n",
      "1  [[-0.7846153846153846, -0.8461538461538461, -4...  \n",
      "2  [[-0.7846153846153846, -0.8461538461538461, -4...  \n",
      "3  [[-0.7846153846153846, -0.8461538461538461, -4...  \n",
      "4  [[-0.7846153846153846, -0.8461538461538461, -4...  \n",
      "(590, 2)\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "duration = 10 # Duration in seconds\n",
    "num_clips = 10 \n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "df = emg_annotations[[\"myo_left_timestamps\", \"description\", \"myo_left_readings\", \"myo_right_timestamps\", \"myo_right_readings\"]].tail(-1)\n",
    "# Assuming your DataFrame is named df\n",
    "processed_data_list = df.apply(process_row, axis=1, args=(num_samples, duration, num_clips))\n",
    "\n",
    "# Flatten the list of lists into a single list of tuples\n",
    "processed_data_tuples = [item for sublist in processed_data_list for item in sublist]\n",
    "\n",
    "# Convert the list of tuples to a DataFrame\n",
    "processed_data = pd.DataFrame(processed_data_tuples, columns=['description', 'myo_readings'])\n",
    "print(processed_data.head())\n",
    "print(processed_data.shape)\n",
    "pd.to_pickle(processed_data, \"processed_data.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egovision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
