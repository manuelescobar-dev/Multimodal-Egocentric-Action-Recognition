{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import butter, filtfilt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ActionNet/train_EMG_augmented.pkl', 'rb') as f:\n",
    "    train_data = pd.read_pickle(f)\n",
    "    \n",
    "with open('data/ActionNet/test_EMG_augmented.pkl', 'rb') as f:\n",
    "    test_data = pd.read_pickle(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Labels column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 classes\n",
      "{'Slice bread': 0, 'Clean a plate with a towel': 1, 'Pour water from a pitcher into a glass': 2, 'Slice a potato': 3, 'Spread jelly on a bread slice': 4, 'Peel a cucumber': 5, 'Load dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils': 6, 'Set table: 3 each large/small plates, bowls, mugs, glasses, sets of utensils': 7, 'Unload dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils': 8, 'Clear cutting board': 9, 'Get items from cabinets: 3 each large/small plates, bowls, mugs, glasses, sets of utensils': 10, 'Spread almond butter on a bread slice': 11, 'Clean a plate with a sponge': 12, 'Open/close a jar of almond butter': 13, 'Peel a potato': 14, 'Slice a cucumber': 15, 'Get/replace items from refrigerator/cabinets/drawers': 16, 'Stack on table: 3 each large/small plates, bowls': 17, 'Clean a pan with a towel': 18, 'Clean a pan with a sponge': 19}\n"
     ]
    }
   ],
   "source": [
    "classes ={'Slice a potato', 'Spread jelly on a bread slice', 'Load dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Unload dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Clear cutting board', 'Get items from cabinets: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Spread almond butter on a bread slice', 'Clean a plate with a sponge', 'Slice a cucumber', 'Clean a pan with a sponge', 'Slice bread', 'Clean a plate with a towel', 'Pour water from a pitcher into a glass', 'Peel a cucumber', 'Set table: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Open/close a jar of almond butter', 'Peel a potato', 'Get/replace items from refrigerator/cabinets/drawers', 'Stack on table: 3 each large/small plates, bowls', 'Clean a pan with a towel'}\n",
    "classes_map = {c: i for i, c in enumerate(classes)}\n",
    "print(len(classes_map),\"classes\")\n",
    "print(classes_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_synonyms(description):\n",
    "    if description==\"Get items from refrigerator/cabinets/drawers\":\n",
    "        return \"Get/replace items from refrigerator/cabinets/drawers\"\n",
    "    elif description==\"Open a jar of almond butter\":\n",
    "        return \"Open/close a jar of almond butter\"\n",
    "    else:\n",
    "        return description\n",
    "    \n",
    "def filter_dataset(data, name):\n",
    "    filtered_dataset = data.copy()\n",
    "    filtered_dataset['description'] = filtered_dataset['description'].apply(remove_synonyms)\n",
    "    classes = filtered_dataset['description'].unique()\n",
    "    print(\"Number of classes found: \", len(classes))\n",
    "    print(\"Mapping:\",classes_map)\n",
    "    filtered_dataset['label'] = filtered_dataset['description'].apply(lambda x: classes_map[x])\n",
    "    print(filtered_dataset.head(2))\n",
    "    print(\"Saving filtered dataset...\")\n",
    "    pd.to_pickle(filtered_dataset, os.path.join(DATA_PATH, f'ActionNet_{name}_filtered.pkl'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes found:  7\n",
      "Mapping: {'Slice bread': 0, 'Clean a plate with a towel': 1, 'Pour water from a pitcher into a glass': 2, 'Slice a potato': 3, 'Spread jelly on a bread slice': 4, 'Peel a cucumber': 5, 'Load dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils': 6, 'Set table: 3 each large/small plates, bowls, mugs, glasses, sets of utensils': 7, 'Unload dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils': 8, 'Clear cutting board': 9, 'Get items from cabinets: 3 each large/small plates, bowls, mugs, glasses, sets of utensils': 10, 'Spread almond butter on a bread slice': 11, 'Clean a plate with a sponge': 12, 'Open/close a jar of almond butter': 13, 'Peel a potato': 14, 'Slice a cucumber': 15, 'Get/replace items from refrigerator/cabinets/drawers': 16, 'Stack on table: 3 each large/small plates, bowls': 17, 'Clean a pan with a towel': 18, 'Clean a pan with a sponge': 19}\n",
      "                          description  start   stop  \\\n",
      "34  Open/close a jar of almond butter  68655  69122   \n",
      "23                Clear cutting board  59260  60075   \n",
      "\n",
      "                                  myo_left_timestamps  \\\n",
      "34  [1655241428.172756, 1655241428.176256, 1655241...   \n",
      "23  [1655241111.499361, 1655241111.506861, 1655241...   \n",
      "\n",
      "                                    myo_left_readings  \\\n",
      "34  [[3, 34, 3, 0, -1, -3, -5, -4], [5, 28, 22, 7,...   \n",
      "23  [[-5, 24, -2, -43, -40, -12, -9, -23], [-60, -...   \n",
      "\n",
      "                                 myo_right_timestamps  \\\n",
      "34  [1655241428.171255, 1655241428.1752572, 165524...   \n",
      "23  [1655241111.502361, 1655241111.509861, 1655241...   \n",
      "\n",
      "                                   myo_right_readings Subject  label  \n",
      "34  [[-3, 0, 11, 16, 0, 2, -1, -3], [-3, -9, -19, ...   S04_1     13  \n",
      "23  [[-2, 2, 13, 11, -8, -3, 0, -1], [0, -2, -14, ...   S04_1      9  \n",
      "Saving filtered dataset...\n"
     ]
    }
   ],
   "source": [
    "filter_dataset(s04_test, \"test_S04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rectify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = 160  # Sampling frequency\n",
    "CUTOFF = 5  # Cutoff frequency\n",
    "NUM_CHANNELS=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify_signal(data):\n",
    "    return np.abs(data)\n",
    "\n",
    "def filter_signal(data, fs, cutoff, num_channels):\n",
    "    for i in range(num_channels):\n",
    "        data[:,i] = low_pass_filter(data[:,i], fs, cutoff)\n",
    "    return data\n",
    "\n",
    "def low_pass_filter(data, fs, cutoff, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, data, padlen=5)\n",
    "\n",
    "def normalization(data, mean, std):\n",
    "    \"\"\"Normalize with mean and std\n",
    "    data: (n_samples, n_channels)\n",
    "    mean and std: (n_channels,)\n",
    "    \"\"\"\n",
    "    return (data - mean) / std\n",
    "    \n",
    "\n",
    "def preprocessing(data, steps):\n",
    "    for step in steps:\n",
    "        data.apply(step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40    [[4, 12, 21, -21, 3, -2, -5, 7], [-6, -5, -5, ...\n",
      "40    [[-5, -7, -6, -66, -24, -23, -6, -14], [-5, -2...\n",
      "40    [[-7, -12, -21, -38, 5, -10, -15, -22], [0, 2,...\n",
      "40    [[2, -1, -3, -27, 0, -4, 0, -1], [-4, 5, 4, 5,...\n",
      "40    [[1, -4, -4, 0, -2, -1, -1, 3], [1, 5, -3, 12,...\n",
      "Name: myo_left_readings, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data[\"myo_left_readings\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40    [[4, 12, 21, 21, 3, 2, 5, 7], [6, 5, 5, 48, 3,...\n",
      "40    [[5, 7, 6, 66, 24, 23, 6, 14], [5, 2, 6, 38, 8...\n",
      "40    [[7, 12, 21, 38, 5, 10, 15, 22], [0, 2, 3, 10,...\n",
      "40    [[2, 1, 3, 27, 0, 4, 0, 1], [4, 5, 4, 5, 7, 7,...\n",
      "40    [[1, 4, 4, 0, 2, 1, 1, 3], [1, 5, 3, 12, 2, 1,...\n",
      "Name: myo_left_readings, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Rectify signal\n",
    "rectified_data = train_data.copy()\n",
    "rectified_data[\"myo_left_readings\"] = rectified_data[\"myo_left_readings\"].apply(rectify_signal)\n",
    "print(rectified_data[\"myo_left_readings\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40    [[6, 11, 22, 18, 2, 1, 5, 8], [6, 11, 20, 18, ...\n",
      "40    [[4, 6, 3, 65, 25, 22, 5, 10], [3, 6, 5, 59, 2...\n",
      "40    [[5, 12, 22, 35, 2, 9, 14, 21], [5, 11, 20, 32...\n",
      "40    [[3, 1, 2, 26, 0, 3, 0, 0], [3, 2, 3, 24, 1, 4...\n",
      "40    [[1, 4, 4, 1, 0, 1, 1, 2], [1, 3, 4, 2, 1, 1, ...\n",
      "Name: myo_left_readings, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Low pass filter\n",
    "filtered_data = rectified_data.copy()\n",
    "filtered_data[\"myo_left_readings\"]= filtered_data[\"myo_left_readings\"].apply(filter_signal, args=(FS, CUTOFF, NUM_CHANNELS))\n",
    "print(filtered_data[\"myo_left_readings\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.83767894 13.11577493 14.54656682 15.66527495 16.68707235 12.93012465\n",
      " 10.64835843 10.58289213] [4.86291377 4.11740436 4.45829986 5.06286368 5.6143549  4.56827959\n",
      " 3.66215016 3.88714868]\n"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "normalized_data = filtered_data.copy()\n",
    "normalized_data[\"myo_left_mean\"] = normalized_data[\"myo_left_readings\"].apply(lambda x: np.mean(x, axis=0))\n",
    "normalized_data[\"myo_left_std\"] = normalized_data[\"myo_left_readings\"].apply(lambda x: np.std(x, axis=0))\n",
    "myo_left_mean = np.mean(normalized_data[\"myo_left_mean\"].to_list(), axis=0)\n",
    "myo_left_std = np.mean(normalized_data[\"myo_left_std\"].to_list(), axis=0)\n",
    "print(myo_left_mean, myo_left_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN=[13.36730503, 12.64401049, 14.07886228, 15.19383317, 16.18250797, 12.46924118, 10.17692475, 10.10188793]\n",
    "STD = [4.66570959, 3.92417575, 4.24558945, 4.84317504, 5.39038114, 4.37708144, 3.5060197, 3.72504386]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    sides=[\"left\", \"right\"]\n",
    "    data = data.copy()\n",
    "    for side in sides:\n",
    "        column = f\"myo_{side}_readings\"\n",
    "        #print(data[column].head(1))\n",
    "        data[column] = data[column].apply(rectify_signal)\n",
    "        #print(data[column].head(1))\n",
    "        data[column]= data[column].apply(filter_signal, args=(FS, CUTOFF, NUM_CHANNELS))\n",
    "        #print(data[column].head(1))\n",
    "        data[column] = data[column].apply(normalization, args=(MEAN, STD))\n",
    "        #print(data[column].head(1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed=preprocessing(train_data)\n",
    "pd.to_pickle(processed, os.path.join(\"data\",\"ActionNet\", \"train_EMG_augmented.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
