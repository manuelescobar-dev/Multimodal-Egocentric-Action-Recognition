{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR=\"data\"\n",
    "ANNOTATIONS_DIR = \"train_val\"\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR,\"raw\")\n",
    "TEMP_DATA_DIR = os.path.join(DATA_DIR,\"temp\")\n",
    "FINAL_DATA_DIR = os.path.join(DATA_DIR,\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        df = pd.read_pickle(f)\n",
    "    return df\n",
    "\n",
    "def save_data(df, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pd.to_pickle(df, f)\n",
    "        \n",
    "def save_step(train_data, test_data, step):\n",
    "    save_data(train_data, os.path.join(TEMP_DATA_DIR, f\"train_{step}.pkl\"))\n",
    "    save_data(test_data, os.path.join(TEMP_DATA_DIR, f\"test_{step}.pkl\"))\n",
    "\n",
    "        \n",
    "def dataset_info(data):\n",
    "    print(\"Dataset shape: \", data.shape)\n",
    "    print(\"Dataset columns: \", data.columns)\n",
    "    # Number of classes\n",
    "    print(\"Number of classes: \", len(data['description'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = load_data('train_val/train.pkl')\n",
    "test_split = load_data('train_val/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (527, 4)\n",
      "Dataset columns:  Index(['index', 'file', 'description', 'labels'], dtype='object')\n",
      "Number of classes:  22\n",
      "Dataset shape:  (59, 4)\n",
      "Dataset columns:  Index(['index', 'file', 'description', 'labels'], dtype='object')\n",
      "Number of classes:  20\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_split)\n",
    "dataset_info(test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"remove_duplicates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes ={'Slice a potato', 'Spread jelly on a bread slice', 'Load dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Unload dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Clear cutting board', 'Get items from cabinets: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Spread almond butter on a bread slice', 'Clean a plate with a sponge', 'Slice a cucumber', 'Clean a pan with a sponge', 'Slice bread', 'Clean a plate with a towel', 'Pour water from a pitcher into a glass', 'Peel a cucumber', 'Set table: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Open/close a jar of almond butter', 'Peel a potato', 'Get/replace items from refrigerator/cabinets/drawers', 'Stack on table: 3 each large/small plates, bowls', 'Clean a pan with a towel'}\n",
    "classes_map = {c: i for i, c in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_synonyms(description):\n",
    "    if description==\"Get items from refrigerator/cabinets/drawers\":\n",
    "        return \"Get/replace items from refrigerator/cabinets/drawers\"\n",
    "    elif description==\"Open a jar of almond butter\":\n",
    "        return \"Open/close a jar of almond butter\"\n",
    "    else:\n",
    "        return description\n",
    "    \n",
    "def filter_dataset(data, name, step=STEP):\n",
    "    filtered_dataset = data.copy()\n",
    "    classes = filtered_dataset['description'].unique()\n",
    "    print(f\"{len(classes)} classes found.\")\n",
    "    filtered_dataset['description'] = filtered_dataset['description'].apply(remove_synonyms)\n",
    "    classes = filtered_dataset['description'].unique()\n",
    "    print(f\"{len(classes)} classes after removing synonyms.\")\n",
    "    filtered_dataset['label'] = filtered_dataset['description'].apply(lambda x: classes_map[x])\n",
    "    # Drop column labels\n",
    "    filtered_dataset = filtered_dataset.drop(columns=['labels'])\n",
    "    return filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 classes found.\n",
      "20 classes after removing synonyms.\n",
      "20 classes found.\n",
      "19 classes after removing synonyms.\n"
     ]
    }
   ],
   "source": [
    "train_split_filtered = filter_dataset(train_split, \"train\")\n",
    "test_split_filtered = filter_dataset(test_split, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (527, 4)\n",
      "Dataset columns:  Index(['index', 'file', 'description', 'label'], dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (59, 4)\n",
      "Dataset columns:  Index(['index', 'file', 'description', 'label'], dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_split_filtered)\n",
    "dataset_info(test_split_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_split_filtered, test_split_filtered, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"merge\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, \"train_remove_duplicates.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, \"test_remove_duplicates.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(mode):\n",
    "    if mode==\"train\":\n",
    "        data = load_data(os.path.join(TEMP_DATA_DIR, \"train_remove_duplicates.pkl\"))\n",
    "    elif mode==\"test\":\n",
    "        data = load_data(os.path.join(TEMP_DATA_DIR, \"test_remove_duplicates.pkl\"))\n",
    "    rows = []\n",
    "    for tup in data.iterrows():\n",
    "        row = tup[1].copy()\n",
    "        file = row[\"file\"]\n",
    "        idx = row[\"index\"]\n",
    "        emg = load_data(os.path.join(RAW_DATA_DIR, file))\n",
    "        emg = emg.iloc[idx].copy()\n",
    "        emg[\"subject\"]=file.split('.')[0]\n",
    "        emg[\"label\"]=row[\"label\"]\n",
    "        emg[\"description\"]=row[\"description\"]\n",
    "        rows.append(emg)\n",
    "    merged = pd.DataFrame(rows)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = merge(\"train\")\n",
    "test_data = merge(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (527, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (59, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_data)\n",
    "dataset_info(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_data, test_data, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"augment\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, f\"train_merge.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, f\"test_merge.pkl\"))\n",
    "DURATION = 10\n",
    "NUM_CLIPS=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each row of the DataFrame\n",
    "def data_augmentation(data:pd.DataFrame, duration, num_clips=None):\n",
    "    if num_clips is None:\n",
    "        augmented=[]\n",
    "        for tup in data.iterrows():\n",
    "            row = tup[1].copy()\n",
    "            tot_time =  row[\"stop\"]- row[\"start\"]\n",
    "            if tot_time>duration:\n",
    "                cuts = np.arange(row[\"start\"], row[\"stop\"], duration)[:-1]\n",
    "                for i, c in enumerate(cuts):\n",
    "                    new_row = row.copy()\n",
    "                    new_row[\"start\"] = c\n",
    "                    end = c+duration\n",
    "                    if i==len(cuts)-1:\n",
    "                        end = row[\"stop\"]\n",
    "                    new_row[\"stop\"] = end\n",
    "                    left_indexes=(new_row[\"myo_left_timestamps\"]>=c) & (new_row[\"myo_left_timestamps\"]<end)\n",
    "                    right_indexes=(new_row[\"myo_right_timestamps\"]>=c) & (new_row[\"myo_right_timestamps\"]<end)\n",
    "                    new_row[\"myo_left_timestamps\"] = new_row[\"myo_left_timestamps\"][left_indexes]\n",
    "                    new_row[\"myo_right_timestamps\"] = new_row[\"myo_right_timestamps\"][right_indexes]\n",
    "                    new_row[\"myo_left_readings\"] = new_row[\"myo_left_readings\"][left_indexes,:]\n",
    "                    new_row[\"myo_right_readings\"] = new_row[\"myo_right_readings\"][right_indexes,:]\n",
    "                    augmented.append(new_row)\n",
    "            else:\n",
    "                augmented.append(row)\n",
    "        return pd.DataFrame(augmented)\n",
    "    else:\n",
    "        augmented=[]\n",
    "        for tup in data.iterrows():\n",
    "            row = tup[1].copy()\n",
    "            tot_time =  row[\"stop\"]- row[\"start\"]\n",
    "            duration = min(duration, tot_time)\n",
    "            highest_offset=max(row[\"start\"], row[\"stop\"]-duration)\n",
    "            cuts = np.linspace(row[\"start\"], highest_offset, num_clips)\n",
    "            for c in cuts:\n",
    "                new_row = row.copy()\n",
    "                new_row[\"start\"] = c\n",
    "                if c+duration>row[\"stop\"]:\n",
    "                    new_row[\"stop\"] = row[\"stop\"]\n",
    "                else:\n",
    "                    new_row[\"stop\"] = c+duration\n",
    "                left_indexes=(new_row[\"myo_left_timestamps\"]>=c) & (new_row[\"myo_left_timestamps\"]<=c+duration)\n",
    "                right_indexes=(new_row[\"myo_right_timestamps\"]>=c) & (new_row[\"myo_right_timestamps\"]<=c+duration)\n",
    "                new_row[\"myo_left_timestamps\"] = new_row[\"myo_left_timestamps\"][left_indexes]\n",
    "                new_row[\"myo_right_timestamps\"] = new_row[\"myo_right_timestamps\"][right_indexes]\n",
    "                new_row[\"myo_left_readings\"] = new_row[\"myo_left_readings\"][left_indexes,:]\n",
    "                new_row[\"myo_right_readings\"] = new_row[\"myo_right_readings\"][right_indexes,:]\n",
    "                augmented.append(new_row)\n",
    "        a = pd.DataFrame(augmented)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_augmented = data_augmentation(train_data, DURATION, NUM_CLIPS)\n",
    "test_data_augmented = data_augmentation(test_data, DURATION, NUM_CLIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (1615, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (175, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_data_augmented)\n",
    "dataset_info(test_data_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_data_augmented, test_data_augmented, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"emg\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, f\"train_augment.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, f\"test_augment.pkl\"))\n",
    "FS = 160  # Sampling frequency\n",
    "CUTOFF = 5  # Cutoff frequency\n",
    "NUM_CHANNELS=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify_signal(data):\n",
    "    return np.abs(data)\n",
    "\n",
    "def filter_signal(data):\n",
    "    for i in range(NUM_CHANNELS):\n",
    "        data[:,i] = low_pass_filter(data[:,i])\n",
    "    return data\n",
    "\n",
    "def low_pass_filter(data, order=5):\n",
    "    nyquist = 0.5 * FS\n",
    "    normal_cutoff = CUTOFF / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, data, padlen=5)\n",
    "\n",
    "def normalization(data, mean, std):\n",
    "    \"\"\"Normalize with mean and std\n",
    "    data: (n_samples, n_channels)\n",
    "    mean and std: (n_channels,)\n",
    "    \"\"\"\n",
    "    return (data - mean) / std\n",
    "\n",
    "def mean_std(data):\n",
    "    sides=[\"left\", \"right\"]\n",
    "    means=[]\n",
    "    stds=[]\n",
    "    for s in sides:\n",
    "        normalized_data = data.copy()\n",
    "        normalized_data[f\"myo_{s}_mean\"] = normalized_data[f\"myo_{s}_readings\"].apply(lambda x: np.mean(x, axis=0))\n",
    "        normalized_data[f\"myo_{s}_std\"] = normalized_data[f\"myo_{s}_readings\"].apply(lambda x: np.std(x, axis=0))\n",
    "        means.append(np.mean(normalized_data[f\"myo_{s}_mean\"].to_list(), axis=0))\n",
    "        stds.append(np.mean(normalized_data[f\"myo_{s}_std\"].to_list(), axis=0))\n",
    "    return (means[0], stds[0]), (means[1], stds[1])\n",
    "\n",
    "def preprocess(train_data, test_data, normalize=False):\n",
    "    # Preprocess train data\n",
    "    train = train_data.copy()\n",
    "    steps=[rectify_signal, filter_signal]\n",
    "    sides=[\"left\", \"right\"]\n",
    "    for side in sides:\n",
    "        for step in steps:\n",
    "            train[f\"myo_{side}_readings\"] = train[f\"myo_{side}_readings\"].apply(step)\n",
    "    if normalize:\n",
    "        (left_mean, left_std), (right_mean, right_std) = mean_std(train)\n",
    "        print(left_mean, left_std, right_mean, right_std)\n",
    "        train[f\"myo_left_readings\"] = train[f\"myo_left_readings\"].apply(normalization, args=(left_mean, left_std))\n",
    "        train[f\"myo_right_readings\"] = train[f\"myo_right_readings\"].apply(normalization, args=(right_mean, right_std))\n",
    "    # Preprocess test data\n",
    "    test = test_data.copy()\n",
    "    for side in sides:\n",
    "        for step in steps:\n",
    "            test[f\"myo_{side}_readings\"] = test[f\"myo_{side}_readings\"].apply(step)\n",
    "    if normalize:\n",
    "        test[f\"myo_left_readings\"] = test[f\"myo_left_readings\"].apply(normalization, args=(left_mean, left_std))\n",
    "        test[f\"myo_right_readings\"] = test[f\"myo_right_readings\"].apply(normalization, args=(right_mean, right_std))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.64600982 11.35153198 12.17744467 13.35750256 15.96943605 12.65458934\n",
      "  9.65763968  9.24195575] [6.49283663 5.35442506 5.76315647 6.62730788 8.203181   7.03001626\n",
      " 5.10985681 5.43732915] [12.48313688 16.29807953 19.10324209 16.01123291 12.36344188  9.606444\n",
      " 11.86239741 10.36038249] [6.6928324  9.25251641 9.31084078 7.9843301  6.30713079 5.07553273\n",
      " 7.17754754 6.1290284 ]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_train, preprocessed_test = preprocess(train_data, test_data, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (1615, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (175, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(preprocessed_train)\n",
    "dataset_info(preprocessed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    myo_left_readings  \\\n",
      "40  [[-0.8695752159287641, -0.06565260932103263, 1...   \n",
      "40  [[-1.639654656472295, -1.9332667575250082, -2....   \n",
      "10  [[-1.4856387683635888, -2.1200281723454055, -0...   \n",
      "10  [[-1.4856387683635888, -2.1200281723454055, -0...   \n",
      "10  [[-0.40752755160264553, 3.856337101907316, 3.4...   \n",
      "\n",
      "                                   myo_right_readings  \n",
      "40  [[-1.7157365056813212, -1.977632757112052, 0.8...  \n",
      "40  [[-1.267495788077133, -1.2210818155922791, -1....  \n",
      "10  [[-1.5663229331465918, -0.8968456977980909, -1...  \n",
      "10  [[-0.9686686430076739, -1.0049244037294869, -1...  \n",
      "10  [[0.6748806548743504, -1.113003109660883, -2.2...  \n",
      "                                    myo_left_readings  \\\n",
      "4   [[-1.7936705445810013, 5.723951250111291, 2.57...   \n",
      "4   [[-0.09949577538523315, 0.49463163514016, 3.26...   \n",
      "4   [[-0.09949577538523315, 2.3622457833441355, -0...   \n",
      "4   [[0.3625518889408854, -0.9994596834230204, -2....   \n",
      "34  [[-1.3316228802548826, 3.4828142722665207, -1....   \n",
      "\n",
      "                                   myo_right_readings  \n",
      "4   [[-1.1180822155424033, 0.07586265558447414, -1...  \n",
      "4   [[2.6172570978258336, -0.24837346220971418, -1...  \n",
      "4   [[1.123121372478539, -1.6533966393178636, 2.45...  \n",
      "4   [[-0.8192550704729443, -0.6806882859352986, 3....  \n",
      "34  [[-1.4169093606118623, -1.7614753452492597, -0...  \n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_train[[\"myo_left_readings\",\"myo_right_readings\"]].head())\n",
    "print(preprocessed_test[[\"myo_left_readings\",\"myo_right_readings\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(preprocessed_train, preprocessed_test, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Multimodal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"multimodal\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, f\"train_emg.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, f\"test_emg.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rgb_data = train_data.loc[train_data[\"subject\"]==\"S04_1\"]\n",
    "test_rgb_data = test_data.loc[test_data[\"subject\"]==\"S04_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (165, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n",
      "Dataset shape:  (17, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  7\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_rgb_data)\n",
    "dataset_info(test_rgb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_rgb_data, test_rgb_data, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add RGB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"multimodal_with_frames\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, f\"train_multimodal.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, f\"test_multimodal.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frames(data):\n",
    "    data = data.copy()\n",
    "    fps=29.67\n",
    "    offset=load_data(os.path.join(RAW_DATA_DIR, \"S04_1.pkl\")).iloc[1][\"start\"]\n",
    "    data[\"start_frame\"]=(data[\"start\"]-offset)*fps\n",
    "    data[\"stop_frame\"]=(data[\"stop\"]-offset)*fps\n",
    "    #convert column to int\n",
    "    data[[\"start_frame\",\"stop_frame\"]]=data[[\"start_frame\",\"stop_frame\"]].astype(int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_with_frames = add_frames(train_data)\n",
    "test_data_with_frames = add_frames(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (165, 11)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label', 'start_frame', 'stop_frame'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n",
      "Dataset shape:  (17, 11)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label', 'start_frame', 'stop_frame'],\n",
      "      dtype='object')\n",
      "Number of classes:  7\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_data_with_frames)\n",
    "dataset_info(test_data_with_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    start_frame  stop_frame\n",
      "10        16413       16710\n",
      "10        16710       17006\n",
      "10        17006       17303\n",
      "10        17303       17600\n",
      "10        17600       17896\n",
      "    start_frame  stop_frame\n",
      "34        43132       43599\n",
      "23        33737       34033\n",
      "23        34033       34552\n",
      "26        38068       38582\n",
      "56        60882       61179\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_frames[[\"start_frame\",\"stop_frame\"]].head())\n",
    "print(test_data_with_frames[[\"start_frame\",\"stop_frame\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_data_with_frames, test_data_with_frames, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emg = load_data(os.path.join(TEMP_DATA_DIR, \"train_emg.pkl\"))\n",
    "test_emg = load_data(os.path.join(TEMP_DATA_DIR, \"test_emg.pkl\"))\n",
    "train_rgb = load_data(os.path.join(TEMP_DATA_DIR, \"train_multimodal_with_frames.pkl\"))\n",
    "test_rgb = load_data(os.path.join(TEMP_DATA_DIR, \"test_multimodal_with_frames.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "train_emg = train_emg.reset_index(drop=True)\n",
    "test_emg = test_emg.reset_index(drop=True)\n",
    "train_rgb = train_rgb.reset_index(drop=True)\n",
    "test_rgb = test_rgb.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (1615, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (175, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_emg)\n",
    "dataset_info(test_emg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description         start  \\\n",
      "0                      Spread jelly on a bread slice  1.657739e+09   \n",
      "1                      Spread jelly on a bread slice  1.657739e+09   \n",
      "2  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "3  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "4  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "\n",
      "           stop                                myo_left_timestamps  \\\n",
      "0  1.657739e+09  [1657738827.4506874, 1657738827.458187, 165773...   \n",
      "1  1.657739e+09  [1657738837.447678, 1657738837.455178, 1657738...   \n",
      "2  1.655241e+09  [1655240527.6204886, 1655240527.624489, 165524...   \n",
      "3  1.655241e+09  [1655240537.617971, 1655240537.629471, 1655240...   \n",
      "4  1.655241e+09  [1655240547.619455, 1655240547.623455, 1655240...   \n",
      "\n",
      "                                   myo_left_readings  \\\n",
      "0  [[-0.8695752159287641, -0.06565260932103263, 1...   \n",
      "1  [[-1.639654656472295, -1.9332667575250082, -2....   \n",
      "2  [[-1.4856387683635888, -2.1200281723454055, -0...   \n",
      "3  [[-1.4856387683635888, -2.1200281723454055, -0...   \n",
      "4  [[-0.40752755160264553, 3.856337101907316, 3.4...   \n",
      "\n",
      "                                myo_right_timestamps  \\\n",
      "0  [1657738827.447178, 1657738827.454177, 1657738...   \n",
      "1  [1657738837.453177, 1657738837.4536786, 165773...   \n",
      "2  [1655240527.6189904, 1655240527.626494, 165524...   \n",
      "3  [1655240537.616971, 1655240537.624471, 1655240...   \n",
      "4  [1655240547.618455, 1655240547.622455, 1655240...   \n",
      "\n",
      "                                  myo_right_readings subject  label  \n",
      "0  [[-1.7157365056813212, -1.977632757112052, 0.8...   S08_1     15  \n",
      "1  [[-1.267495788077133, -1.2210818155922791, -1....   S08_1     15  \n",
      "2  [[-1.5663229331465918, -0.8968456977980909, -1...   S04_1      0  \n",
      "3  [[-0.9686686430076739, -1.0049244037294869, -1...   S04_1      0  \n",
      "4  [[0.6748806548743504, -1.113003109660883, -2.2...   S04_1      0  \n",
      "                         description         start          stop  \\\n",
      "0                    Peel a cucumber  1.655172e+09  1.655172e+09   \n",
      "1                    Peel a cucumber  1.655172e+09  1.655172e+09   \n",
      "2                    Peel a cucumber  1.655172e+09  1.655172e+09   \n",
      "3                    Peel a cucumber  1.655172e+09  1.655172e+09   \n",
      "4  Open/close a jar of almond butter  1.655241e+09  1.655241e+09   \n",
      "\n",
      "                                 myo_left_timestamps  \\\n",
      "0  [1655172364.999943, 1655172365.0039296, 165517...   \n",
      "1  [1655172374.9979873, 1655172375.005463, 165517...   \n",
      "2  [1655172384.999026, 1655172385.003014, 1655172...   \n",
      "3  [1655172395.0010586, 1655172395.008531, 165517...   \n",
      "4  [1655241428.172756, 1655241428.176256, 1655241...   \n",
      "\n",
      "                                   myo_left_readings  \\\n",
      "0  [[-1.7936705445810013, 5.723951250111291, 2.57...   \n",
      "1  [[-0.09949577538523315, 0.49463163514016, 3.26...   \n",
      "2  [[-0.09949577538523315, 2.3622457833441355, -0...   \n",
      "3  [[0.3625518889408854, -0.9994596834230204, -2....   \n",
      "4  [[-1.3316228802548826, 3.4828142722665207, -1....   \n",
      "\n",
      "                                myo_right_timestamps  \\\n",
      "0  [1655172364.997953, 1655172365.0014415, 165517...   \n",
      "1  [1655172374.998986, 1655172375.002473, 1655172...   \n",
      "2  [1655172385.0005205, 1655172385.007994, 165517...   \n",
      "3  [1655172395.0015585, 1655172395.012522, 165517...   \n",
      "4  [1655241428.171255, 1655241428.1752572, 165524...   \n",
      "\n",
      "                                  myo_right_readings subject  label  \n",
      "0  [[-1.1180822155424033, 0.07586265558447414, -1...   S02_2      2  \n",
      "1  [[2.6172570978258336, -0.24837346220971418, -1...   S02_2      2  \n",
      "2  [[1.123121372478539, -1.6533966393178636, 2.45...   S02_2      2  \n",
      "3  [[-0.8192550704729443, -0.6806882859352986, 3....   S02_2      2  \n",
      "4  [[-1.4169093606118623, -1.7614753452492597, -0...   S04_1     13  \n"
     ]
    }
   ],
   "source": [
    "print(train_emg.head())\n",
    "print(test_emg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (165, 11)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label', 'start_frame', 'stop_frame'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n",
      "Dataset shape:  (17, 11)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label', 'start_frame', 'stop_frame'],\n",
      "      dtype='object')\n",
      "Number of classes:  7\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_rgb)\n",
    "dataset_info(test_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description         start  \\\n",
      "0  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "1  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "2  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "3  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "4  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "\n",
      "           stop                                myo_left_timestamps  \\\n",
      "0  1.655241e+09  [1655240527.6204886, 1655240527.624489, 165524...   \n",
      "1  1.655241e+09  [1655240537.617971, 1655240537.629471, 1655240...   \n",
      "2  1.655241e+09  [1655240547.619455, 1655240547.623455, 1655240...   \n",
      "3  1.655241e+09  [1655240557.61744, 1655240557.62094, 165524055...   \n",
      "4  1.655241e+09  [1655240567.6185899, 1655240567.63009, 1655240...   \n",
      "\n",
      "                                   myo_left_readings  \\\n",
      "0  [[-1.4856387683635888, -2.1200281723454055, -0...   \n",
      "1  [[-1.4856387683635888, -2.1200281723454055, -0...   \n",
      "2  [[-0.40752755160264553, 3.856337101907316, 3.4...   \n",
      "3  [[-0.8695752159287641, 2.9225300278053283, -1....   \n",
      "4  [[-0.8695752159287641, 1.2416772944217502, 2.3...   \n",
      "\n",
      "                                myo_right_timestamps  \\\n",
      "0  [1655240527.6189904, 1655240527.626494, 165524...   \n",
      "1  [1655240537.616971, 1655240537.624471, 1655240...   \n",
      "2  [1655240547.618455, 1655240547.622455, 1655240...   \n",
      "3  [1655240557.61944, 1655240557.62344, 165524055...   \n",
      "4  [1655240567.61709, 1655240567.6210918, 1655240...   \n",
      "\n",
      "                                  myo_right_readings subject  label  \\\n",
      "0  [[-1.5663229331465918, -0.8968456977980909, -1...   S04_1      0   \n",
      "1  [[-0.9686686430076739, -1.0049244037294869, -1...   S04_1      0   \n",
      "2  [[0.6748806548743504, -1.113003109660883, -2.2...   S04_1      0   \n",
      "3  [[-2.4628043683549685, 1.3728071267612274, 2.3...   S04_1      0   \n",
      "4  [[-0.9686686430076739, -0.24837346220971418, 0...   S04_1      0   \n",
      "\n",
      "   start_frame  stop_frame  \n",
      "0        16413       16710  \n",
      "1        16710       17006  \n",
      "2        17006       17303  \n",
      "3        17303       17600  \n",
      "4        17600       17896  \n",
      "                                         description         start  \\\n",
      "0                  Open/close a jar of almond butter  1.655241e+09   \n",
      "1                                Clear cutting board  1.655241e+09   \n",
      "2                                Clear cutting board  1.655241e+09   \n",
      "3              Spread almond butter on a bread slice  1.655241e+09   \n",
      "4  Set table: 3 each large/small plates, bowls, m...  1.655242e+09   \n",
      "\n",
      "           stop                                myo_left_timestamps  \\\n",
      "0  1.655241e+09  [1655241428.172756, 1655241428.176256, 1655241...   \n",
      "1  1.655241e+09  [1655241111.499361, 1655241111.506861, 1655241...   \n",
      "2  1.655241e+09  [1655241121.5048451, 1655241121.512345, 165524...   \n",
      "3  1.655241e+09  [1655241257.474128, 1655241257.4856277, 165524...   \n",
      "4  1.655242e+09  [1655242026.407278, 1655242026.410778, 1655242...   \n",
      "\n",
      "                                   myo_left_readings  \\\n",
      "0  [[-1.3316228802548826, 3.4828142722665207, -1....   \n",
      "1  [[-1.0235911040374703, 1.9887229537033404, -1....   \n",
      "2  [[11.297679944659023, -1.7465053427046107, 3.9...   \n",
      "3  [[6.67720330139784, -0.06565260932103263, -1.9...   \n",
      "4  [[-0.25351166349393933, -2.3067895871658033, -...   \n",
      "\n",
      "                                myo_right_timestamps  \\\n",
      "0  [1655241428.171255, 1655241428.1752572, 165524...   \n",
      "1  [1655241111.502361, 1655241111.509861, 1655241...   \n",
      "2  [1655241121.500345, 1655241121.507845, 1655241...   \n",
      "3  [1655241257.4731278, 1655241257.477128, 165524...   \n",
      "4  [1655242026.4102788, 1655242026.425279, 165524...   \n",
      "\n",
      "                                  myo_right_readings subject  label  \\\n",
      "0  [[-1.4169093606118623, -1.7614753452492597, -0...   S04_1     13   \n",
      "1  [[-1.7157365056813212, -1.6533966393178636, -0...   S04_1      5   \n",
      "2  [[0.37605350980489144, 0.5081774793100585, -0....   S04_1      5   \n",
      "3  [[-0.6698414979382149, -1.113003109660883, -1....   S04_1      1   \n",
      "4  [[-0.9686686430076739, -0.8968456977980909, -0...   S04_1     11   \n",
      "\n",
      "   start_frame  stop_frame  \n",
      "0        43132       43599  \n",
      "1        33737       34033  \n",
      "2        34033       34552  \n",
      "3        38068       38582  \n",
      "4        60882       61179  \n"
     ]
    }
   ],
   "source": [
    "print(train_rgb.head())\n",
    "print(test_rgb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(train_emg, os.path.join(FINAL_DATA_DIR, \"train_EMG.pkl\"))\n",
    "save_data(test_emg, os.path.join(FINAL_DATA_DIR, \"test_EMG.pkl\"))\n",
    "save_data(train_rgb, os.path.join(FINAL_DATA_DIR, \"train_MULTIMODAL.pkl\"))\n",
    "save_data(test_rgb, os.path.join(FINAL_DATA_DIR, \"test_MULTIMODAL.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
