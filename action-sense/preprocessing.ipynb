{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR=\"data\"\n",
    "ANNOTATIONS_DIR = \"train_val\"\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR,\"raw\")\n",
    "TEMP_DATA_DIR = os.path.join(DATA_DIR,\"temp\")\n",
    "FINAL_DATA_DIR = os.path.join(DATA_DIR,\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        df = pd.read_pickle(f)\n",
    "    return df\n",
    "\n",
    "def save_data(df, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pd.to_pickle(df, f)\n",
    "        \n",
    "def save_step(train_data, test_data, step):\n",
    "    save_data(train_data, os.path.join(TEMP_DATA_DIR, f\"train_{step}.pkl\"))\n",
    "    save_data(test_data, os.path.join(TEMP_DATA_DIR, f\"test_{step}.pkl\"))\n",
    "\n",
    "        \n",
    "def dataset_info(data):\n",
    "    print(\"Dataset shape: \", data.shape)\n",
    "    print(\"Dataset columns: \", data.columns)\n",
    "    # Number of classes\n",
    "    print(\"Number of classes: \", len(data['description'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = load_data('train_val/train.pkl')\n",
    "test_split = load_data('train_val/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (527, 4)\n",
      "Dataset columns:  Index(['index', 'file', 'description', 'labels'], dtype='object')\n",
      "Number of classes:  22\n",
      "Dataset shape:  (59, 4)\n",
      "Dataset columns:  Index(['index', 'file', 'description', 'labels'], dtype='object')\n",
      "Number of classes:  20\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_split)\n",
    "dataset_info(test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"remove_duplicates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes ={'Slice a potato', 'Spread jelly on a bread slice', 'Load dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Unload dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Clear cutting board', 'Get items from cabinets: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Spread almond butter on a bread slice', 'Clean a plate with a sponge', 'Slice a cucumber', 'Clean a pan with a sponge', 'Slice bread', 'Clean a plate with a towel', 'Pour water from a pitcher into a glass', 'Peel a cucumber', 'Set table: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Open/close a jar of almond butter', 'Peel a potato', 'Get/replace items from refrigerator/cabinets/drawers', 'Stack on table: 3 each large/small plates, bowls', 'Clean a pan with a towel'}\n",
    "classes_map = {c: i for i, c in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_synonyms(description):\n",
    "    if description==\"Get items from refrigerator/cabinets/drawers\":\n",
    "        return \"Get/replace items from refrigerator/cabinets/drawers\"\n",
    "    elif description==\"Open a jar of almond butter\":\n",
    "        return \"Open/close a jar of almond butter\"\n",
    "    else:\n",
    "        return description\n",
    "    \n",
    "def filter_dataset(data, name, step=STEP):\n",
    "    filtered_dataset = data.copy()\n",
    "    classes = filtered_dataset['description'].unique()\n",
    "    print(f\"{len(classes)} classes found.\")\n",
    "    filtered_dataset['description'] = filtered_dataset['description'].apply(remove_synonyms)\n",
    "    classes = filtered_dataset['description'].unique()\n",
    "    print(f\"{len(classes)} classes after removing synonyms.\")\n",
    "    filtered_dataset['label'] = filtered_dataset['description'].apply(lambda x: classes_map[x])\n",
    "    # Drop column labels\n",
    "    filtered_dataset = filtered_dataset.drop(columns=['labels'])\n",
    "    return filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 classes found.\n",
      "20 classes after removing synonyms.\n",
      "20 classes found.\n",
      "19 classes after removing synonyms.\n"
     ]
    }
   ],
   "source": [
    "train_split_filtered = filter_dataset(train_split, \"train\")\n",
    "test_split_filtered = filter_dataset(test_split, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (527, 4)\n",
      "Dataset columns:  Index(['index', 'file', 'description', 'label'], dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (59, 4)\n",
      "Dataset columns:  Index(['index', 'file', 'description', 'label'], dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_split_filtered)\n",
    "dataset_info(test_split_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_split_filtered, test_split_filtered, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"merge\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, \"train_remove_duplicates.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, \"test_remove_duplicates.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(mode):\n",
    "    if mode==\"train\":\n",
    "        data = load_data(os.path.join(TEMP_DATA_DIR, \"train_remove_duplicates.pkl\"))\n",
    "    elif mode==\"test\":\n",
    "        data = load_data(os.path.join(TEMP_DATA_DIR, \"test_remove_duplicates.pkl\"))\n",
    "    rows = []\n",
    "    for tup in data.iterrows():\n",
    "        row = tup[1].copy()\n",
    "        file = row[\"file\"]\n",
    "        idx = row[\"index\"]\n",
    "        emg = load_data(os.path.join(RAW_DATA_DIR, file))\n",
    "        emg = emg.iloc[idx].copy()\n",
    "        emg[\"subject\"]=file.split('.')[0]\n",
    "        emg[\"label\"]=row[\"label\"]\n",
    "        emg[\"description\"]=row[\"description\"]\n",
    "        rows.append(emg)\n",
    "    merged = pd.DataFrame(rows)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = merge(\"train\")\n",
    "test_data = merge(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (527, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (59, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_data)\n",
    "dataset_info(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_data, test_data, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"augment\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, f\"train_merge.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, f\"test_merge.pkl\"))\n",
    "DURATION = 10\n",
    "NUM_CLIPS=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each row of the DataFrame\n",
    "def data_augmentation(data:pd.DataFrame, duration, num_clips=None):\n",
    "    if num_clips is None:\n",
    "        augmented=[]\n",
    "        for tup in data.iterrows():\n",
    "            row = tup[1].copy()\n",
    "            tot_time =  row[\"stop\"]- row[\"start\"]\n",
    "            if tot_time>duration:\n",
    "                cuts = np.arange(row[\"start\"], row[\"stop\"], duration)[:-1]\n",
    "                for i, c in enumerate(cuts):\n",
    "                    new_row = row.copy()\n",
    "                    new_row[\"start\"] = c\n",
    "                    end = c+duration\n",
    "                    if i==len(cuts)-1:\n",
    "                        end = row[\"stop\"]\n",
    "                    new_row[\"stop\"] = end\n",
    "                    left_indexes=(new_row[\"myo_left_timestamps\"]>=c) & (new_row[\"myo_left_timestamps\"]<end)\n",
    "                    right_indexes=(new_row[\"myo_right_timestamps\"]>=c) & (new_row[\"myo_right_timestamps\"]<end)\n",
    "                    new_row[\"myo_left_timestamps\"] = new_row[\"myo_left_timestamps\"][left_indexes]\n",
    "                    new_row[\"myo_right_timestamps\"] = new_row[\"myo_right_timestamps\"][right_indexes]\n",
    "                    new_row[\"myo_left_readings\"] = new_row[\"myo_left_readings\"][left_indexes,:]\n",
    "                    new_row[\"myo_right_readings\"] = new_row[\"myo_right_readings\"][right_indexes,:]\n",
    "                    augmented.append(new_row)\n",
    "            else:\n",
    "                augmented.append(row)\n",
    "        return pd.DataFrame(augmented)\n",
    "    else:\n",
    "        augmented=[]\n",
    "        for tup in data.iterrows():\n",
    "            row = tup[1].copy()\n",
    "            tot_time =  row[\"stop\"]- row[\"start\"]\n",
    "            duration = min(duration, tot_time)\n",
    "            highest_offset=max(row[\"start\"], row[\"stop\"]-duration)\n",
    "            cuts = np.linspace(row[\"start\"], highest_offset, num_clips)\n",
    "            for c in cuts:\n",
    "                new_row = row.copy()\n",
    "                new_row[\"start\"] = c\n",
    "                if c+duration>row[\"stop\"]:\n",
    "                    new_row[\"stop\"] = row[\"stop\"]\n",
    "                else:\n",
    "                    new_row[\"stop\"] = c+duration\n",
    "                left_indexes=(new_row[\"myo_left_timestamps\"]>=c) & (new_row[\"myo_left_timestamps\"]<=c+duration)\n",
    "                right_indexes=(new_row[\"myo_right_timestamps\"]>=c) & (new_row[\"myo_right_timestamps\"]<=c+duration)\n",
    "                new_row[\"myo_left_timestamps\"] = new_row[\"myo_left_timestamps\"][left_indexes]\n",
    "                new_row[\"myo_right_timestamps\"] = new_row[\"myo_right_timestamps\"][right_indexes]\n",
    "                new_row[\"myo_left_readings\"] = new_row[\"myo_left_readings\"][left_indexes,:]\n",
    "                new_row[\"myo_right_readings\"] = new_row[\"myo_right_readings\"][right_indexes,:]\n",
    "                augmented.append(new_row)\n",
    "        a = pd.DataFrame(augmented)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_augmented = data_augmentation(train_data, DURATION, NUM_CLIPS)\n",
    "test_data_augmented = data_augmentation(test_data, DURATION, NUM_CLIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (3311, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (362, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_data_augmented)\n",
    "dataset_info(test_data_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_data_augmented, test_data_augmented, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"emg\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, f\"train_augment.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, f\"test_augment.pkl\"))\n",
    "FS = 160  # Sampling frequency\n",
    "CUTOFF = 5  # Cutoff frequency\n",
    "NUM_CHANNELS=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify_signal(data):\n",
    "    return np.abs(data)\n",
    "\n",
    "def filter_signal(data):\n",
    "    for i in range(NUM_CHANNELS):\n",
    "        data[:,i] = low_pass_filter(data[:,i])\n",
    "    return data\n",
    "\n",
    "def low_pass_filter(data, order=5):\n",
    "    nyquist = 0.5 * FS\n",
    "    normal_cutoff = CUTOFF / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, data, padlen=5)\n",
    "\n",
    "def normalization(data, mean, std):\n",
    "    \"\"\"Normalize with mean and std\n",
    "    data: (n_samples, n_channels)\n",
    "    mean and std: (n_channels,)\n",
    "    \"\"\"\n",
    "    return (data - mean) / std\n",
    "\n",
    "def mean_std(data):\n",
    "    sides=[\"left\", \"right\"]\n",
    "    means=[]\n",
    "    stds=[]\n",
    "    for s in sides:\n",
    "        normalized_data = data.copy()\n",
    "        normalized_data[f\"myo_{s}_mean\"] = normalized_data[f\"myo_{s}_readings\"].apply(lambda x: np.mean(x, axis=0))\n",
    "        normalized_data[f\"myo_{s}_std\"] = normalized_data[f\"myo_{s}_readings\"].apply(lambda x: np.std(x, axis=0))\n",
    "        means.append(np.mean(normalized_data[f\"myo_{s}_mean\"].to_list(), axis=0))\n",
    "        stds.append(np.mean(normalized_data[f\"myo_{s}_std\"].to_list(), axis=0))\n",
    "    return (means[0], stds[0]), (means[1], stds[1])\n",
    "\n",
    "def preprocess(train_data, test_data, normalize=False):\n",
    "    # Preprocess train data\n",
    "    train = train_data.copy()\n",
    "    steps=[rectify_signal, filter_signal]\n",
    "    sides=[\"left\", \"right\"]\n",
    "    for side in sides:\n",
    "        for step in steps:\n",
    "            train[f\"myo_{side}_readings\"] = train[f\"myo_{side}_readings\"].apply(step)\n",
    "    if normalize:\n",
    "        (left_mean, left_std), (right_mean, right_std) = mean_std(train)\n",
    "        print(left_mean, left_std, right_mean, right_std)\n",
    "        train[f\"myo_left_readings\"] = train[f\"myo_left_readings\"].apply(normalization, args=(left_mean, left_std))\n",
    "        train[f\"myo_right_readings\"] = train[f\"myo_right_readings\"].apply(normalization, args=(right_mean, right_std))\n",
    "    # Preprocess test data\n",
    "    test = test_data.copy()\n",
    "    for side in sides:\n",
    "        for step in steps:\n",
    "            test[f\"myo_{side}_readings\"] = test[f\"myo_{side}_readings\"].apply(step)\n",
    "    if normalize:\n",
    "        test[f\"myo_left_readings\"] = test[f\"myo_left_readings\"].apply(normalization, args=(left_mean, left_std))\n",
    "        test[f\"myo_right_readings\"] = test[f\"myo_right_readings\"].apply(normalization, args=(right_mean, right_std))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.56361771 11.21051396 11.9618695  13.23233926 16.07757608 12.7148602\n",
      "  9.6654832   9.25045687] [5.91995267 4.91895658 5.27592846 6.09308719 7.61099604 6.4389358\n",
      " 4.69545215 4.98935264] [12.53663034 16.36586102 19.19948703 15.95498182 12.36631464  9.65959738\n",
      " 11.89806297 10.40399191] [6.20287008 8.56938787 8.76395084 7.43965282 5.96235598 4.7795494\n",
      " 6.65425632 5.69748396]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_train, preprocessed_test = preprocess(train_data, test_data, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (3311, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (362, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(preprocessed_train)\n",
    "dataset_info(preprocessed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    myo_left_readings  \\\n",
      "40  [[-0.939807803185361, -0.0427964656607138, 1.9...   \n",
      "40  [[-1.9533294198689748, -2.279043082640766, -1....   \n",
      "40  [[-1.784409150421706, -2.0757479356425796, -2....   \n",
      "40  [[-1.784409150421706, -2.279043082640766, -1.8...   \n",
      "10  [[-1.6154888809744368, -2.279043082640766, -0....   \n",
      "\n",
      "                                   myo_right_readings  \n",
      "40  [[-1.8598858582399078, -2.143194040127815, 0.8...  \n",
      "40  [[1.0419966212858311, 1.5910283417032969, 0.31...  \n",
      "40  [[-1.3762387783189514, -1.3263328941022594, -1...  \n",
      "40  [[1.6868593945137733, -0.8595550963733705, -2....  \n",
      "10  [[-1.6986701649329223, -0.9762495458055928, -1...  \n",
      "                                   myo_left_readings  \\\n",
      "4  [[-1.9533294198689748, 6.259353091283071, 2.85...   \n",
      "4  [[1.7629165079709426, -0.6526819066552735, -0....   \n",
      "4  [[-0.09520645594901608, 0.567088975333846, 3.6...   \n",
      "4  [[-0.26412672539628507, 2.1934501513193387, -1...   \n",
      "4  [[-0.09520645594901608, 2.6000404453157118, -0...   \n",
      "\n",
      "                                  myo_right_readings  \n",
      "4  [[-1.2150230850119659, 0.07400049908440755, -1...  \n",
      "4  [[-0.7313760050910093, -2.143194040127815, -2....  \n",
      "4  [[2.8153692476626717, -0.27608284921225923, -1...  \n",
      "4  [[3.782663407504585, 1.2409449934066301, -1.73...  \n",
      "4  [[1.2032123145928169, -1.7931106918311486, 2.6...  \n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_train[[\"myo_left_readings\",\"myo_right_readings\"]].head())\n",
    "print(preprocessed_test[[\"myo_left_readings\",\"myo_right_readings\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(preprocessed_train, preprocessed_test, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Multimodal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"multimodal\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, f\"train_emg.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, f\"test_emg.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rgb_data = train_data.loc[train_data[\"subject\"]==\"S04_1\"]\n",
    "test_rgb_data = test_data.loc[test_data[\"subject\"]==\"S04_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (335, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n",
      "Dataset shape:  (33, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  7\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_rgb_data)\n",
    "dataset_info(test_rgb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_rgb_data, test_rgb_data, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add RGB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"multimodal_with_frames\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, f\"train_multimodal.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, f\"test_multimodal.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frames(data):\n",
    "    data = data.copy()\n",
    "    fps=29.67\n",
    "    offset=load_data(os.path.join(RAW_DATA_DIR, \"S04_1.pkl\")).iloc[1][\"start\"]\n",
    "    data[\"start_frame\"]=(data[\"start\"]-offset)*fps\n",
    "    data[\"stop_frame\"]=(data[\"stop\"]-offset)*fps\n",
    "    #convert column to int\n",
    "    data[[\"start_frame\",\"stop_frame\"]]=data[[\"start_frame\",\"stop_frame\"]].astype(int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_with_frames = add_frames(train_data)\n",
    "test_data_with_frames = add_frames(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (335, 11)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label', 'start_frame', 'stop_frame'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n",
      "Dataset shape:  (33, 11)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label', 'start_frame', 'stop_frame'],\n",
      "      dtype='object')\n",
      "Number of classes:  7\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_data_with_frames)\n",
    "dataset_info(test_data_with_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    start_frame  stop_frame\n",
      "10        16413       16561\n",
      "10        16561       16710\n",
      "10        16710       16858\n",
      "10        16858       17006\n",
      "10        17006       17155\n",
      "    start_frame  stop_frame\n",
      "34        43132       43281\n",
      "34        43281       43429\n",
      "34        43429       43599\n",
      "23        33737       33885\n",
      "23        33885       34033\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_frames[[\"start_frame\",\"stop_frame\"]].head())\n",
    "print(test_data_with_frames[[\"start_frame\",\"stop_frame\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_data_with_frames, test_data_with_frames, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emg = load_data(os.path.join(TEMP_DATA_DIR, \"train_emg.pkl\"))\n",
    "test_emg = load_data(os.path.join(TEMP_DATA_DIR, \"test_emg.pkl\"))\n",
    "train_rgb = load_data(os.path.join(TEMP_DATA_DIR, \"train_multimodal_with_frames.pkl\"))\n",
    "test_rgb = load_data(os.path.join(TEMP_DATA_DIR, \"test_multimodal_with_frames.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "train_emg = train_emg.reset_index(drop=True)\n",
    "test_emg = test_emg.reset_index(drop=True)\n",
    "train_rgb = train_rgb.reset_index(drop=True)\n",
    "test_rgb = test_rgb.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (3311, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (362, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_emg)\n",
    "dataset_info(test_emg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description         start  \\\n",
      "0                      Spread jelly on a bread slice  1.657739e+09   \n",
      "1                      Spread jelly on a bread slice  1.657739e+09   \n",
      "2                      Spread jelly on a bread slice  1.657739e+09   \n",
      "3                      Spread jelly on a bread slice  1.657739e+09   \n",
      "4  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "\n",
      "           stop                                myo_left_timestamps  \\\n",
      "0  1.657739e+09  [1657738827.4506874, 1657738827.458187, 165773...   \n",
      "1  1.657739e+09  [1657738832.453177, 1657738832.456678, 1657738...   \n",
      "2  1.657739e+09  [1657738837.447678, 1657738837.455178, 1657738...   \n",
      "3  1.657739e+09  [1657738842.451178, 1657738842.4621787, 165773...   \n",
      "4  1.655241e+09  [1655240527.6204886, 1655240527.624489, 165524...   \n",
      "\n",
      "                                   myo_left_readings  \\\n",
      "0  [[-0.939807803185361, -0.0427964656607138, 1.9...   \n",
      "1  [[-1.9533294198689748, -2.279043082640766, -1....   \n",
      "2  [[-1.784409150421706, -2.0757479356425796, -2....   \n",
      "3  [[-1.784409150421706, -2.279043082640766, -1.8...   \n",
      "4  [[-1.6154888809744368, -2.279043082640766, -0....   \n",
      "\n",
      "                                myo_right_timestamps  \\\n",
      "0  [1657738827.447178, 1657738827.454177, 1657738...   \n",
      "1  [1657738832.449678, 1657738832.457178, 1657738...   \n",
      "2  [1657738837.453177, 1657738837.4536786, 165773...   \n",
      "3  [1657738842.446185, 1657738842.4576807, 165773...   \n",
      "4  [1655240527.6189904, 1655240527.626494, 165524...   \n",
      "\n",
      "                                  myo_right_readings subject  label  \n",
      "0  [[-1.8598858582399078, -2.143194040127815, 0.8...   S08_1     15  \n",
      "1  [[1.0419966212858311, 1.5910283417032969, 0.31...   S08_1     15  \n",
      "2  [[-1.3762387783189514, -1.3263328941022594, -1...   S08_1     15  \n",
      "3  [[1.6868593945137733, -0.8595550963733705, -2....   S08_1     15  \n",
      "4  [[-1.6986701649329223, -0.9762495458055928, -1...   S04_1      0  \n",
      "       description         start          stop  \\\n",
      "0  Peel a cucumber  1.655172e+09  1.655172e+09   \n",
      "1  Peel a cucumber  1.655172e+09  1.655172e+09   \n",
      "2  Peel a cucumber  1.655172e+09  1.655172e+09   \n",
      "3  Peel a cucumber  1.655172e+09  1.655172e+09   \n",
      "4  Peel a cucumber  1.655172e+09  1.655172e+09   \n",
      "\n",
      "                                 myo_left_timestamps  \\\n",
      "0  [1655172364.999943, 1655172365.0039296, 165517...   \n",
      "1  [1655172369.997225, 1655172370.0071926, 165517...   \n",
      "2  [1655172374.9979873, 1655172375.005463, 165517...   \n",
      "3  [1655172380.000748, 1655172380.0042396, 165517...   \n",
      "4  [1655172384.999026, 1655172385.003014, 1655172...   \n",
      "\n",
      "                                   myo_left_readings  \\\n",
      "0  [[-1.9533294198689748, 6.259353091283071, 2.85...   \n",
      "1  [[1.7629165079709426, -0.6526819066552735, -0....   \n",
      "2  [[-0.09520645594901608, 0.567088975333846, 3.6...   \n",
      "3  [[-0.26412672539628507, 2.1934501513193387, -1...   \n",
      "4  [[-0.09520645594901608, 2.6000404453157118, -0...   \n",
      "\n",
      "                                myo_right_timestamps  \\\n",
      "0  [1655172364.997953, 1655172365.0014415, 165517...   \n",
      "1  [1655172370.000211, 1655172370.0037005, 165517...   \n",
      "2  [1655172374.998986, 1655172375.002473, 1655172...   \n",
      "3  [1655172379.997759, 1655172380.001249, 1655172...   \n",
      "4  [1655172385.0005205, 1655172385.007994, 165517...   \n",
      "\n",
      "                                  myo_right_readings subject  label  \n",
      "0  [[-1.2150230850119659, 0.07400049908440755, -1...   S02_2      2  \n",
      "1  [[-0.7313760050910093, -2.143194040127815, -2....   S02_2      2  \n",
      "2  [[2.8153692476626717, -0.27608284921225923, -1...   S02_2      2  \n",
      "3  [[3.782663407504585, 1.2409449934066301, -1.73...   S02_2      2  \n",
      "4  [[1.2032123145928169, -1.7931106918311486, 2.6...   S02_2      2  \n"
     ]
    }
   ],
   "source": [
    "print(train_emg.head())\n",
    "print(test_emg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (335, 11)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label', 'start_frame', 'stop_frame'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n",
      "Dataset shape:  (33, 11)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label', 'start_frame', 'stop_frame'],\n",
      "      dtype='object')\n",
      "Number of classes:  7\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_rgb)\n",
    "dataset_info(test_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description         start  \\\n",
      "0  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "1  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "2  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "3  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "4  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "\n",
      "           stop                                myo_left_timestamps  \\\n",
      "0  1.655241e+09  [1655240527.6204886, 1655240527.624489, 165524...   \n",
      "1  1.655241e+09  [1655240532.626479, 1655240532.6304793, 165524...   \n",
      "2  1.655241e+09  [1655240537.617971, 1655240537.629471, 1655240...   \n",
      "3  1.655241e+09  [1655240542.624464, 1655240542.628464, 1655240...   \n",
      "4  1.655241e+09  [1655240547.619455, 1655240547.623455, 1655240...   \n",
      "\n",
      "                                   myo_left_readings  \\\n",
      "0  [[-1.6154888809744368, -2.279043082640766, -0....   \n",
      "1  [[-0.09520645594901608, 1.3802695633265922, -0...   \n",
      "2  [[-1.6154888809744368, -2.279043082640766, -0....   \n",
      "3  [[-1.1087280726326298, -0.0427964656607138, -0...   \n",
      "4  [[-0.433046994843554, 4.226401621301204, 3.798...   \n",
      "\n",
      "                                myo_right_timestamps  \\\n",
      "0  [1655240527.6189904, 1655240527.626494, 165524...   \n",
      "1  [1655240532.622479, 1655240532.6259794, 165524...   \n",
      "2  [1655240537.616971, 1655240537.624471, 1655240...   \n",
      "3  [1655240542.619467, 1655240542.6269684, 165524...   \n",
      "4  [1655240547.618455, 1655240547.622455, 1655240...   \n",
      "\n",
      "                                  myo_right_readings subject  label  \\\n",
      "0  [[-1.6986701649329223, -0.9762495458055928, -1...   S04_1      0   \n",
      "1  [[-2.3435329381608643, -2.493277388424482, -1....   S04_1      0   \n",
      "2  [[-1.0538073917049804, -1.092943995237815, -1....   S04_1      0   \n",
      "3  [[-0.8925916983979949, -0.15938839978003697, 2...   S04_1      0   \n",
      "4  [[0.7195652346718602, -1.2096384446700372, -2....   S04_1      0   \n",
      "\n",
      "   start_frame  stop_frame  \n",
      "0        16413       16561  \n",
      "1        16561       16710  \n",
      "2        16710       16858  \n",
      "3        16858       17006  \n",
      "4        17006       17155  \n",
      "                         description         start          stop  \\\n",
      "0  Open/close a jar of almond butter  1.655241e+09  1.655241e+09   \n",
      "1  Open/close a jar of almond butter  1.655241e+09  1.655241e+09   \n",
      "2  Open/close a jar of almond butter  1.655241e+09  1.655241e+09   \n",
      "3                Clear cutting board  1.655241e+09  1.655241e+09   \n",
      "4                Clear cutting board  1.655241e+09  1.655241e+09   \n",
      "\n",
      "                                 myo_left_timestamps  \\\n",
      "0  [1655241428.172756, 1655241428.176256, 1655241...   \n",
      "1  [1655241433.171251, 1655241433.1787486, 165524...   \n",
      "2  [1655241438.1742415, 1655241438.182239, 165524...   \n",
      "3  [1655241111.499361, 1655241111.506861, 1655241...   \n",
      "4  [1655241116.502358, 1655241116.5098581, 165524...   \n",
      "\n",
      "                                   myo_left_readings  \\\n",
      "0  [[-1.4465686115271679, 3.8198113273048313, -2....   \n",
      "1  [[0.4115543523927908, 5.852762797286697, 2.660...   \n",
      "2  [[4.634561088574515, -2.279043082640766, 6.830...   \n",
      "3  [[-1.1087280726326298, 2.1934501513193387, -2....   \n",
      "4  [[6.492684052494474, 0.7703841223320325, 0.386...   \n",
      "\n",
      "                                myo_right_timestamps  \\\n",
      "0  [1655241428.171255, 1655241428.1752572, 165524...   \n",
      "1  [1655241433.174249, 1655241433.182251, 1655241...   \n",
      "2  [1655241438.1697378, 1655241438.177238, 165524...   \n",
      "3  [1655241111.502361, 1655241111.509861, 1655241...   \n",
      "4  [1655241116.497853, 1655241116.505353, 1655241...   \n",
      "\n",
      "                                  myo_right_readings subject  label  \\\n",
      "0  [[-1.5374544716259368, -1.9098051412633708, -0...   S04_1     13   \n",
      "1  [[-1.0538073917049804, -1.4430273435344818, -0...   S04_1     13   \n",
      "2  [[-1.3762387783189514, -0.8595550963733705, 5....   S04_1     13   \n",
      "3  [[-1.8598858582399078, -1.7931106918311486, -1...   S04_1      5   \n",
      "4  [[-2.0211015515468933, -1.9098051412633708, -0...   S04_1      5   \n",
      "\n",
      "   start_frame  stop_frame  \n",
      "0        43132       43281  \n",
      "1        43281       43429  \n",
      "2        43429       43599  \n",
      "3        33737       33885  \n",
      "4        33885       34033  \n"
     ]
    }
   ],
   "source": [
    "print(train_rgb.head())\n",
    "print(test_rgb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(train_emg, os.path.join(FINAL_DATA_DIR, \"train_EMG.pkl\"))\n",
    "save_data(test_emg, os.path.join(FINAL_DATA_DIR, \"test_EMG.pkl\"))\n",
    "save_data(train_rgb, os.path.join(FINAL_DATA_DIR, \"train_MULTIMODAL.pkl\"))\n",
    "save_data(test_rgb, os.path.join(FINAL_DATA_DIR, \"test_MULTIMODAL.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
