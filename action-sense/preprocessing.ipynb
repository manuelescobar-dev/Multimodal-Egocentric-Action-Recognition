{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR=\"data\"\n",
    "ANNOTATIONS_DIR = \"train_val\"\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR,\"raw\")\n",
    "TEMP_DATA_DIR = os.path.join(DATA_DIR,\"temp\")\n",
    "FINAL_DATA_DIR = os.path.join(DATA_DIR,\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        df = pd.read_pickle(f)\n",
    "    return df\n",
    "\n",
    "def save_data(df, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pd.to_pickle(df, f)\n",
    "        \n",
    "def save_step(train_data, test_data, step):\n",
    "    save_data(train_data, os.path.join(TEMP_DATA_DIR, f\"train_{step}.pkl\"))\n",
    "    save_data(test_data, os.path.join(TEMP_DATA_DIR, f\"test_{step}.pkl\"))\n",
    "\n",
    "        \n",
    "def dataset_info(data):\n",
    "    print(\"Dataset shape: \", data.shape)\n",
    "    print(\"Dataset columns: \", data.columns)\n",
    "    # Number of classes\n",
    "    print(\"Number of classes: \", len(data['description'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = load_data('train_val/train.pkl')\n",
    "test_split = load_data('train_val/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (527, 4)\n",
      "Dataset columns:  Index(['index', 'file', 'description', 'labels'], dtype='object')\n",
      "Number of classes:  22\n",
      "Dataset shape:  (59, 4)\n",
      "Dataset columns:  Index(['index', 'file', 'description', 'labels'], dtype='object')\n",
      "Number of classes:  20\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_split)\n",
    "dataset_info(test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"remove_duplicates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes ={'Slice a potato', 'Spread jelly on a bread slice', 'Load dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Unload dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Clear cutting board', 'Get items from cabinets: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Spread almond butter on a bread slice', 'Clean a plate with a sponge', 'Slice a cucumber', 'Clean a pan with a sponge', 'Slice bread', 'Clean a plate with a towel', 'Pour water from a pitcher into a glass', 'Peel a cucumber', 'Set table: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Open/close a jar of almond butter', 'Peel a potato', 'Get/replace items from refrigerator/cabinets/drawers', 'Stack on table: 3 each large/small plates, bowls', 'Clean a pan with a towel'}\n",
    "classes_map = {c: i for i, c in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_synonyms(description):\n",
    "    if description==\"Get items from refrigerator/cabinets/drawers\":\n",
    "        return \"Get/replace items from refrigerator/cabinets/drawers\"\n",
    "    elif description==\"Open a jar of almond butter\":\n",
    "        return \"Open/close a jar of almond butter\"\n",
    "    else:\n",
    "        return description\n",
    "    \n",
    "def filter_dataset(data, name, step=STEP):\n",
    "    filtered_dataset = data.copy()\n",
    "    classes = filtered_dataset['description'].unique()\n",
    "    print(f\"{len(classes)} classes found.\")\n",
    "    filtered_dataset['description'] = filtered_dataset['description'].apply(remove_synonyms)\n",
    "    classes = filtered_dataset['description'].unique()\n",
    "    print(f\"{len(classes)} classes after removing synonyms.\")\n",
    "    filtered_dataset['label'] = filtered_dataset['description'].apply(lambda x: classes_map[x])\n",
    "    # Drop column labels\n",
    "    filtered_dataset = filtered_dataset.drop(columns=['labels'])\n",
    "    return filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 classes found.\n",
      "20 classes after removing synonyms.\n",
      "20 classes found.\n",
      "19 classes after removing synonyms.\n"
     ]
    }
   ],
   "source": [
    "train_split_filtered = filter_dataset(train_split, \"train\")\n",
    "test_split_filtered = filter_dataset(test_split, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (527, 4)\n",
      "Dataset columns:  Index(['index', 'file', 'description', 'label'], dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (59, 4)\n",
      "Dataset columns:  Index(['index', 'file', 'description', 'label'], dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_split_filtered)\n",
    "dataset_info(test_split_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_split_filtered, test_split_filtered, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"merge\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, \"train_remove_duplicates.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, \"test_remove_duplicates.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(mode):\n",
    "    if mode==\"train\":\n",
    "        data = load_data(os.path.join(TEMP_DATA_DIR, \"train_remove_duplicates.pkl\"))\n",
    "    elif mode==\"test\":\n",
    "        data = load_data(os.path.join(TEMP_DATA_DIR, \"test_remove_duplicates.pkl\"))\n",
    "    rows = []\n",
    "    for tup in data.iterrows():\n",
    "        row = tup[1].copy()\n",
    "        file = row[\"file\"]\n",
    "        idx = row[\"index\"]\n",
    "        emg = load_data(os.path.join(RAW_DATA_DIR, file))\n",
    "        emg = emg.iloc[idx].copy()\n",
    "        emg[\"subject\"]=file.split('.')[0]\n",
    "        emg[\"label\"]=row[\"label\"]\n",
    "        emg[\"description\"]=row[\"description\"]\n",
    "        rows.append(emg)\n",
    "    merged = pd.DataFrame(rows)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = merge(\"train\")\n",
    "test_data = merge(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (527, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (59, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_data)\n",
    "dataset_info(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_data, test_data, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"augment\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, f\"train_merge.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, f\"test_merge.pkl\"))\n",
    "DURATION = 10\n",
    "NUM_CLIPS=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each row of the DataFrame\n",
    "def data_augmentation(data:pd.DataFrame, duration, num_clips=None):\n",
    "    if num_clips is None:\n",
    "        augmented=[]\n",
    "        for tup in data.iterrows():\n",
    "            row = tup[1].copy()\n",
    "            tot_time =  row[\"stop\"]- row[\"start\"]\n",
    "            if tot_time>duration:\n",
    "                cuts = np.arange(row[\"start\"], row[\"stop\"], duration)[:-1]\n",
    "                for i, c in enumerate(cuts):\n",
    "                    new_row = row.copy()\n",
    "                    new_row[\"start\"] = c\n",
    "                    end = c+duration\n",
    "                    if i==len(cuts)-1:\n",
    "                        end = row[\"stop\"]\n",
    "                    new_row[\"stop\"] = end\n",
    "                    left_indexes=(new_row[\"myo_left_timestamps\"]>=c) & (new_row[\"myo_left_timestamps\"]<end)\n",
    "                    right_indexes=(new_row[\"myo_right_timestamps\"]>=c) & (new_row[\"myo_right_timestamps\"]<end)\n",
    "                    new_row[\"myo_left_timestamps\"] = new_row[\"myo_left_timestamps\"][left_indexes]\n",
    "                    new_row[\"myo_right_timestamps\"] = new_row[\"myo_right_timestamps\"][right_indexes]\n",
    "                    new_row[\"myo_left_readings\"] = new_row[\"myo_left_readings\"][left_indexes,:]\n",
    "                    new_row[\"myo_right_readings\"] = new_row[\"myo_right_readings\"][right_indexes,:]\n",
    "                    augmented.append(new_row)\n",
    "            else:\n",
    "                augmented.append(row)\n",
    "        return pd.DataFrame(augmented)\n",
    "    else:\n",
    "        augmented=[]\n",
    "        for tup in data.iterrows():\n",
    "            row = tup[1].copy()\n",
    "            tot_time =  row[\"stop\"]- row[\"start\"]\n",
    "            duration = min(duration, tot_time)\n",
    "            highest_offset=max(row[\"start\"], row[\"stop\"]-duration)\n",
    "            cuts = np.linspace(row[\"start\"], highest_offset, num_clips)\n",
    "            for c in cuts:\n",
    "                new_row = row.copy()\n",
    "                new_row[\"start\"] = c\n",
    "                if c+duration>row[\"stop\"]:\n",
    "                    new_row[\"stop\"] = row[\"stop\"]\n",
    "                else:\n",
    "                    new_row[\"stop\"] = c+duration\n",
    "                left_indexes=(new_row[\"myo_left_timestamps\"]>=c) & (new_row[\"myo_left_timestamps\"]<=c+duration)\n",
    "                right_indexes=(new_row[\"myo_right_timestamps\"]>=c) & (new_row[\"myo_right_timestamps\"]<=c+duration)\n",
    "                new_row[\"myo_left_timestamps\"] = new_row[\"myo_left_timestamps\"][left_indexes]\n",
    "                new_row[\"myo_right_timestamps\"] = new_row[\"myo_right_timestamps\"][right_indexes]\n",
    "                new_row[\"myo_left_readings\"] = new_row[\"myo_left_readings\"][left_indexes,:]\n",
    "                new_row[\"myo_right_readings\"] = new_row[\"myo_right_readings\"][right_indexes,:]\n",
    "                augmented.append(new_row)\n",
    "        a = pd.DataFrame(augmented)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_augmented = data_augmentation(train_data, DURATION, NUM_CLIPS)\n",
    "test_data_augmented = data_augmentation(test_data, DURATION, NUM_CLIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (10540, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (1180, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_data_augmented)\n",
    "dataset_info(test_data_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_data_augmented, test_data_augmented, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"emg\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, f\"train_augment.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, f\"test_augment.pkl\"))\n",
    "FS = 160  # Sampling frequency\n",
    "CUTOFF = 5  # Cutoff frequency\n",
    "NUM_CHANNELS=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify_signal(data):\n",
    "    return np.abs(data)\n",
    "\n",
    "def filter_signal(data):\n",
    "    for i in range(NUM_CHANNELS):\n",
    "        data[:,i] = low_pass_filter(data[:,i])\n",
    "    return data\n",
    "\n",
    "def low_pass_filter(data, order=5):\n",
    "    nyquist = 0.5 * FS\n",
    "    normal_cutoff = CUTOFF / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, data, padlen=5)\n",
    "\n",
    "def normalization(data, mean, std):\n",
    "    \"\"\"Normalize with mean and std\n",
    "    data: (n_samples, n_channels)\n",
    "    mean and std: (n_channels,)\n",
    "    \"\"\"\n",
    "    return (data - mean) / std\n",
    "\n",
    "def mean_std(data):\n",
    "    sides=[\"left\", \"right\"]\n",
    "    means=[]\n",
    "    stds=[]\n",
    "    for s in sides:\n",
    "        normalized_data = data.copy()\n",
    "        normalized_data[f\"myo_{s}_mean\"] = normalized_data[f\"myo_{s}_readings\"].apply(lambda x: np.mean(x, axis=0))\n",
    "        normalized_data[f\"myo_{s}_std\"] = normalized_data[f\"myo_{s}_readings\"].apply(lambda x: np.std(x, axis=0))\n",
    "        means.append(np.mean(normalized_data[f\"myo_{s}_mean\"].to_list(), axis=0))\n",
    "        stds.append(np.mean(normalized_data[f\"myo_{s}_std\"].to_list(), axis=0))\n",
    "    return (means[0], stds[0]), (means[1], stds[1])\n",
    "\n",
    "def preprocess(train_data, test_data, normalize=False):\n",
    "    # Preprocess train data\n",
    "    train = train_data.copy()\n",
    "    steps=[rectify_signal, filter_signal]\n",
    "    sides=[\"left\", \"right\"]\n",
    "    for side in sides:\n",
    "        for step in steps:\n",
    "            train[f\"myo_{side}_readings\"] = train[f\"myo_{side}_readings\"].apply(step)\n",
    "    if normalize:\n",
    "        (left_mean, left_std), (right_mean, right_std) = mean_std(train)\n",
    "        print(left_mean, left_std, right_mean, right_std)\n",
    "        train[f\"myo_left_readings\"] = train[f\"myo_left_readings\"].apply(normalization, args=(left_mean, left_std))\n",
    "        train[f\"myo_right_readings\"] = train[f\"myo_right_readings\"].apply(normalization, args=(right_mean, right_std))\n",
    "    # Preprocess test data\n",
    "    test = test_data.copy()\n",
    "    for side in sides:\n",
    "        for step in steps:\n",
    "            test[f\"myo_{side}_readings\"] = test[f\"myo_{side}_readings\"].apply(step)\n",
    "    if normalize:\n",
    "        test[f\"myo_left_readings\"] = test[f\"myo_left_readings\"].apply(normalization, args=(left_mean, left_std))\n",
    "        test[f\"myo_right_readings\"] = test[f\"myo_right_readings\"].apply(normalization, args=(right_mean, right_std))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.83767894 13.11577493 14.54656682 15.66527495 16.68707235 12.93012465\n",
      " 10.64835843 10.58289213] [4.86291377 4.11740436 4.45829986 5.06286368 5.6143549  4.56827959\n",
      " 3.66215016 3.88714868] [13.66348284 16.86827578 19.50473562 16.98609403 12.46804998  9.97944208\n",
      " 12.97797236 10.96904905] [4.88247377 6.38570786 6.67814243 5.83467806 4.49633266 3.71481983\n",
      " 5.16284828 4.31314243]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_train, preprocessed_test = preprocess(train_data, test_data, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (10540, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (1180, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(preprocessed_train)\n",
    "dataset_info(preprocessed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    myo_left_readings  \\\n",
      "40  [[-1.611724844692337, -0.5138613413610372, 1.6...   \n",
      "40  [[-2.023000901476728, -1.7282186313955923, -2....   \n",
      "40  [[-1.8173628730845324, -0.2709898833541262, 1....   \n",
      "40  [[-2.2286389298689233, -2.9425759214301475, -2...   \n",
      "40  [[-2.6399149866533147, -2.213961547409414, -2....   \n",
      "\n",
      "                                   myo_right_readings  \n",
      "40  [[-2.593661214426692, -2.954766518282782, 1.12...  \n",
      "40  [[-2.1840327973688884, 0.4904271052454041, 2.1...  \n",
      "40  [[-0.9551475461954783, -2.3283676776412934, 9....  \n",
      "40  [[-1.3647759632532817, 3.779021018613218, 1.72...  \n",
      "40  [[-3.0032896314844955, -2.3283676776412934, 0....  \n",
      "                                   myo_left_readings  \\\n",
      "4  [[-2.84555301504551, 7.015153856853204, 2.7933...   \n",
      "4  [[-0.5835347027313591, -0.028118425347215224, ...   \n",
      "4  [[-2.2286389298689233, 1.4291103226942508, -4....   \n",
      "4  [[-3.4624671002220966, -1.2424757153817703, -2...   \n",
      "4  [[2.089759666367183, -0.9996042573748593, -0.1...   \n",
      "\n",
      "                                  myo_right_readings  \n",
      "4  [[-1.7744043803110852, 0.02062797476428787, -2...  \n",
      "4  [[3.1411366243825563, 9.103411164065868, 1.571...  \n",
      "4  [[-3.0032896314844955, 5.031818699896195, -1.1...  \n",
      "4  [[1.7074371646802442, 10.826007975829963, 12.3...  \n",
      "4  [[-1.7744043803110852, -1.8585685471601772, -2...  \n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_train[[\"myo_left_readings\",\"myo_right_readings\"]].head())\n",
    "print(preprocessed_test[[\"myo_left_readings\",\"myo_right_readings\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(preprocessed_train, preprocessed_test, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Multimodal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"multimodal\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, f\"train_emg.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, f\"test_emg.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rgb_data = train_data.loc[train_data[\"subject\"]==\"S04_1\"]\n",
    "test_rgb_data = test_data.loc[test_data[\"subject\"]==\"S04_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (1020, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n",
      "Dataset shape:  (160, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  7\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_rgb_data)\n",
    "dataset_info(test_rgb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_rgb_data, test_rgb_data, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add RGB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=\"multimodal_with_frames\"\n",
    "train_data = load_data(os.path.join(TEMP_DATA_DIR, f\"train_multimodal.pkl\"))\n",
    "test_data = load_data(os.path.join(TEMP_DATA_DIR, f\"test_multimodal.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frames(data):\n",
    "    data = data.copy()\n",
    "    fps=29.67\n",
    "    offset=load_data(os.path.join(RAW_DATA_DIR, \"S04_1.pkl\")).iloc[1][\"start\"]\n",
    "    data[\"start_frame\"]=(data[\"start\"]-offset)*fps\n",
    "    data[\"stop_frame\"]=(data[\"stop\"]-offset)*fps\n",
    "    #convert column to int\n",
    "    data[[\"start_frame\",\"stop_frame\"]]=data[[\"start_frame\",\"stop_frame\"]].astype(int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_with_frames = add_frames(train_data)\n",
    "test_data_with_frames = add_frames(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (1020, 11)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label', 'start_frame', 'stop_frame'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n",
      "Dataset shape:  (160, 11)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label', 'start_frame', 'stop_frame'],\n",
      "      dtype='object')\n",
      "Number of classes:  7\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_data_with_frames)\n",
    "dataset_info(test_data_with_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    start_frame  stop_frame\n",
      "10        16413       16710\n",
      "10        16507       16804\n",
      "10        16601       16898\n",
      "10        16695       16991\n",
      "10        16789       17085\n",
      "    start_frame  stop_frame\n",
      "34        43132       43429\n",
      "34        43141       43438\n",
      "34        43150       43447\n",
      "34        43159       43456\n",
      "34        43168       43465\n"
     ]
    }
   ],
   "source": [
    "print(train_data_with_frames[[\"start_frame\",\"stop_frame\"]].head())\n",
    "print(test_data_with_frames[[\"start_frame\",\"stop_frame\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_step(train_data_with_frames, test_data_with_frames, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emg = load_data(os.path.join(TEMP_DATA_DIR, \"train_emg.pkl\"))\n",
    "test_emg = load_data(os.path.join(TEMP_DATA_DIR, \"test_emg.pkl\"))\n",
    "train_rgb = load_data(os.path.join(TEMP_DATA_DIR, \"train_multimodal_with_frames.pkl\"))\n",
    "test_rgb = load_data(os.path.join(TEMP_DATA_DIR, \"test_multimodal_with_frames.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "train_emg = train_emg.reset_index(drop=True)\n",
    "test_emg = test_emg.reset_index(drop=True)\n",
    "train_rgb = train_rgb.reset_index(drop=True)\n",
    "test_rgb = test_rgb.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (10540, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  20\n",
      "Dataset shape:  (1180, 9)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_emg)\n",
    "dataset_info(test_emg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     description         start          stop  \\\n",
      "0  Spread jelly on a bread slice  1.657739e+09  1.657739e+09   \n",
      "1  Spread jelly on a bread slice  1.657739e+09  1.657739e+09   \n",
      "2  Spread jelly on a bread slice  1.657739e+09  1.657739e+09   \n",
      "3  Spread jelly on a bread slice  1.657739e+09  1.657739e+09   \n",
      "4  Spread jelly on a bread slice  1.657739e+09  1.657739e+09   \n",
      "\n",
      "                                 myo_left_timestamps  \\\n",
      "0  [1657738827.4506874, 1657738827.458187, 165773...   \n",
      "1  [1657738828.076678, 1657738828.080177, 1657738...   \n",
      "2  [1657738828.710679, 1657738828.718178, 1657738...   \n",
      "3  [1657738829.3326783, 1657738829.340179, 165773...   \n",
      "4  [1657738829.963178, 1657738829.9706826, 165773...   \n",
      "\n",
      "                                   myo_left_readings  \\\n",
      "0  [[-1.611724844692337, -0.5138613413610372, 1.6...   \n",
      "1  [[-2.023000901476728, -1.7282186313955923, -2....   \n",
      "2  [[-1.8173628730845324, -0.2709898833541262, 1....   \n",
      "3  [[-2.2286389298689233, -2.9425759214301475, -2...   \n",
      "4  [[-2.6399149866533147, -2.213961547409414, -2....   \n",
      "\n",
      "                                myo_right_timestamps  \\\n",
      "0  [1657738827.447178, 1657738827.454177, 1657738...   \n",
      "1  [1657738828.07618, 1657738828.083182, 16577388...   \n",
      "2  [1657738828.707178, 1657738828.707678, 1657738...   \n",
      "3  [1657738829.337178, 1657738829.3381786, 165773...   \n",
      "4  [1657738829.965177, 1657738829.969677, 1657738...   \n",
      "\n",
      "                                  myo_right_readings subject  label  \n",
      "0  [[-2.593661214426692, -2.954766518282782, 1.12...   S08_1     10  \n",
      "1  [[-2.1840327973688884, 0.4904271052454041, 2.1...   S08_1     10  \n",
      "2  [[-0.9551475461954783, -2.3283676776412934, 9....   S08_1     10  \n",
      "3  [[-1.3647759632532817, 3.779021018613218, 1.72...   S08_1     10  \n",
      "4  [[-3.0032896314844955, -2.3283676776412934, 0....   S08_1     10  \n",
      "       description         start          stop  \\\n",
      "0  Peel a cucumber  1.655172e+09  1.655172e+09   \n",
      "1  Peel a cucumber  1.655172e+09  1.655172e+09   \n",
      "2  Peel a cucumber  1.655172e+09  1.655172e+09   \n",
      "3  Peel a cucumber  1.655172e+09  1.655172e+09   \n",
      "4  Peel a cucumber  1.655172e+09  1.655172e+09   \n",
      "\n",
      "                                 myo_left_timestamps  \\\n",
      "0  [1655172364.999943, 1655172365.0039296, 165517...   \n",
      "1  [1655172367.01022, 1655172367.0251698, 1655172...   \n",
      "2  [1655172369.02747, 1655172369.0314565, 1655172...   \n",
      "3  [1655172371.037739, 1655172371.045712, 1655172...   \n",
      "4  [1655172373.048013, 1655172373.051503, 1655172...   \n",
      "\n",
      "                                   myo_left_readings  \\\n",
      "0  [[-2.84555301504551, 7.015153856853204, 2.7933...   \n",
      "1  [[-0.5835347027313591, -0.028118425347215224, ...   \n",
      "2  [[-2.2286389298689233, 1.4291103226942508, -4....   \n",
      "3  [[-3.4624671002220966, -1.2424757153817703, -2...   \n",
      "4  [[2.089759666367183, -0.9996042573748593, -0.1...   \n",
      "\n",
      "                                myo_right_timestamps  \\\n",
      "0  [1655172364.997953, 1655172365.0014415, 165517...   \n",
      "1  [1655172367.0112145, 1655172367.015203, 165517...   \n",
      "2  [1655172369.0214875, 1655172369.025472, 165517...   \n",
      "3  [1655172371.042722, 1655172371.0501971, 165517...   \n",
      "4  [1655172373.045028, 1655172373.0525005, 165517...   \n",
      "\n",
      "                                  myo_right_readings subject  label  \n",
      "0  [[-1.7744043803110852, 0.02062797476428787, -2...   S02_2      4  \n",
      "1  [[3.1411366243825563, 9.103411164065868, 1.571...   S02_2      4  \n",
      "2  [[-3.0032896314844955, 5.031818699896195, -1.1...   S02_2      4  \n",
      "3  [[1.7074371646802442, 10.826007975829963, 12.3...   S02_2      4  \n",
      "4  [[-1.7744043803110852, -1.8585685471601772, -2...   S02_2      4  \n"
     ]
    }
   ],
   "source": [
    "print(train_emg.head())\n",
    "print(test_emg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (1020, 11)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label', 'start_frame', 'stop_frame'],\n",
      "      dtype='object')\n",
      "Number of classes:  19\n",
      "Dataset shape:  (160, 11)\n",
      "Dataset columns:  Index(['description', 'start', 'stop', 'myo_left_timestamps',\n",
      "       'myo_left_readings', 'myo_right_timestamps', 'myo_right_readings',\n",
      "       'subject', 'label', 'start_frame', 'stop_frame'],\n",
      "      dtype='object')\n",
      "Number of classes:  7\n"
     ]
    }
   ],
   "source": [
    "dataset_info(train_rgb)\n",
    "dataset_info(test_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description         start  \\\n",
      "0  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "1  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "2  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "3  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "4  Get/replace items from refrigerator/cabinets/d...  1.655241e+09   \n",
      "\n",
      "           stop                                myo_left_timestamps  \\\n",
      "0  1.655241e+09  [1655240527.6204886, 1655240527.624489, 165524...   \n",
      "1  1.655241e+09  [1655240530.7854846, 1655240530.796483, 165524...   \n",
      "2  1.655241e+09  [1655240533.954478, 1655240533.957978, 1655240...   \n",
      "3  1.655241e+09  [1655240537.1189718, 1655240537.126472, 165524...   \n",
      "4  1.655241e+09  [1655240540.2919679, 1655240540.299468, 165524...   \n",
      "\n",
      "                                   myo_left_readings  \\\n",
      "0  [[-2.434276958261119, -3.185447379437058, -1.0...   \n",
      "1  [[-2.6399149866533147, -1.9710900894025032, -1...   \n",
      "2  [[-1.2004487879079457, -0.9996042573748593, 2....   \n",
      "3  [[5.585606149034508, 0.21475303265969578, -1.9...   \n",
      "4  [[-2.434276958261119, -2.9425759214301475, -1....   \n",
      "\n",
      "                                myo_right_timestamps  \\\n",
      "0  [1655240527.6189904, 1655240527.626494, 165524...   \n",
      "1  [1655240530.783988, 1655240530.791488, 1655240...   \n",
      "2  [1655240533.9569817, 1655240533.964479, 165524...   \n",
      "3  [1655240537.122472, 1655240537.125972, 1655240...   \n",
      "4  [1655240540.287467, 1655240540.2949696, 165524...   \n",
      "\n",
      "                                  myo_right_readings subject  label  \\\n",
      "0  [[-2.3888470058977904, -1.3887694166790607, -1...   S04_1      5   \n",
      "1  [[-2.3888470058977904, -2.3283676776412934, -1...   S04_1      5   \n",
      "2  [[-2.3888470058977904, -2.6415670979620374, -2...   S04_1      5   \n",
      "3  [[-2.1840327973688884, 1.1168259458868923, 0.6...   S04_1      5   \n",
      "4  [[-0.34070492060877305, 0.02062797476428787, -...   S04_1      5   \n",
      "\n",
      "   start_frame  stop_frame  \n",
      "0        16413       16710  \n",
      "1        16507       16804  \n",
      "2        16601       16898  \n",
      "3        16695       16991  \n",
      "4        16789       17085  \n",
      "                         description         start          stop  \\\n",
      "0  Open/close a jar of almond butter  1.655241e+09  1.655241e+09   \n",
      "1  Open/close a jar of almond butter  1.655241e+09  1.655241e+09   \n",
      "2  Open/close a jar of almond butter  1.655241e+09  1.655241e+09   \n",
      "3  Open/close a jar of almond butter  1.655241e+09  1.655241e+09   \n",
      "4  Open/close a jar of almond butter  1.655241e+09  1.655241e+09   \n",
      "\n",
      "                                 myo_left_timestamps  \\\n",
      "0  [1655241428.172756, 1655241428.176256, 1655241...   \n",
      "1  [1655241428.472758, 1655241428.476258, 1655241...   \n",
      "2  [1655241428.7727575, 1655241428.776257, 165524...   \n",
      "3  [1655241429.076257, 1655241429.083757, 1655241...   \n",
      "4  [1655241429.376756, 1655241429.384259, 1655241...   \n",
      "\n",
      "                                   myo_left_readings  \\\n",
      "0  [[-2.2286389298689233, 4.1006963607702716, -3....   \n",
      "1  [[-2.434276958261119, -0.2709898833541262, 0.5...   \n",
      "2  [[-2.023000901476728, 2.886339070735717, -2.81...   \n",
      "3  [[-2.2286389298689233, 6.04366802482556, -2.36...   \n",
      "4  [[-0.9948107595157502, 1.1862388646873399, 2.7...   \n",
      "\n",
      "                                myo_right_timestamps  \\\n",
      "0  [1655241428.171255, 1655241428.1752572, 165524...   \n",
      "1  [1655241428.471259, 1655241428.4752564, 165524...   \n",
      "2  [1655241428.779253, 1655241428.7867537, 165524...   \n",
      "3  [1655241429.078755, 1655241429.086253, 1655241...   \n",
      "4  [1655241429.379252, 1655241429.3877525, 165524...   \n",
      "\n",
      "                                  myo_right_readings subject  label  \\\n",
      "0  [[-2.1840327973688884, -2.6415670979620374, -1...   S04_1      0   \n",
      "1  [[-0.7503333376665765, -0.1359717353960842, -0...   S04_1      0   \n",
      "2  [[-2.593661214426692, 0.02062797476428787, -2....   S04_1      0   \n",
      "3  [[0.0689234964490304, 1.2734256560472645, 4.86...   S04_1      0   \n",
      "4  [[-0.5455191291376748, -1.3887694166790607, -1...   S04_1      0   \n",
      "\n",
      "   start_frame  stop_frame  \n",
      "0        43132       43429  \n",
      "1        43141       43438  \n",
      "2        43150       43447  \n",
      "3        43159       43456  \n",
      "4        43168       43465  \n"
     ]
    }
   ],
   "source": [
    "print(train_rgb.head())\n",
    "print(test_rgb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(train_emg, os.path.join(FINAL_DATA_DIR, \"train_EMG.pkl\"))\n",
    "save_data(test_emg, os.path.join(FINAL_DATA_DIR, \"test_EMG.pkl\"))\n",
    "save_data(train_rgb, os.path.join(FINAL_DATA_DIR, \"train_MULTIMODAL.pkl\"))\n",
    "save_data(test_rgb, os.path.join(FINAL_DATA_DIR, \"test_MULTIMODAL.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
